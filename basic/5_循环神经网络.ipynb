{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 循环神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 循环神经网络模块\n",
    "RNN无法有效应对长时依赖问题，时间跨度较大，所以会丢失较前的信息，LSTM (Long Short Term Memory Networks)和GRU (Gated Recurrent Unit)可以一定程度上解决长时依赖问题，但后来提出的注意力attention机制会更加有效"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 原始RNN\n",
    "网络有两个输入：当前时刻$t$的输入$x_t$和$t-1$时刻的隐藏状态$h_{t-1}$\n",
    "- $x_t$的维度：**(seq, batch, feature)**，分别表示序列长度、批量和输入特征维度\n",
    "- $h_{t-1}$的维度：**(layers*direction, batch, hidden)**，分别表示层数乘方向(单向为1，双向为2)，批量和输出维度\n",
    "\n",
    "网络有两个输出：当前时刻$t$的输出$output$和隐藏状态$h_t$\n",
    "- $output$的维度：**(seq, batch, hidden*direction)**，分别表示序列长度，批量和输出维度乘方向(单向为1，双向为2)\n",
    "- $h_t$的维度：**(layers*direction, batch, hidden)**，分别表示层数乘方向(单向为1，双向为2)，批量和输出维度\n",
    "\n",
    "**注意**：$h_{t-1}$和 $h_t$的维度是一致的；在网络初始化时有隐藏状态$h_0$，可以自己指定，如果不指定则默认为0；在单向的RNN中每层只有一个记忆单元，双向的有两个\n",
    "\n",
    "RNN的内部网络计算公式：\n",
    "$$h_t=tanh(w_{ih}*x_t+b_{ih}+w_{hh}*h_{t-1}+b_{hh})$$\n",
    "\n",
    "在PyTorch中使用`nn.RNN(*args, **kargs)`定义，根据参数的定义形式使用`nn.RNN(input_size=20, hidden_size=50, num_layers=2)`和`nn.RNN(20, 50, 2)`定义的结果一致，参数列表如下：\n",
    "\n",
    "|参数|功能|\n",
    "|-|-|\n",
    "|input_size|输入$x_t$的特征维度|\n",
    "|hidden_size|输出(隐藏状态)$h_t$的特征维度|\n",
    "|num_layers|网络层数，默认为**1**|\n",
    "|nonlinearity|非线性激活函数，默认tanh，可选relu|\n",
    "|bias|是否使用偏置，默认使用**True**|\n",
    "|batch_first|决定网络输入维度的顺序，默认顺序为<br>**(seq, batch, feature)**,如果设置为True，<br>顺序变为(batch, seq, feature)|\n",
    "|dropout|参数接收0~1的数值，在除最后一层外<br>的其他层加dropout层，默认为**0**|\n",
    "|bidirectional|设置为True表示双向循环神经网络，<br>默认**False**|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意：0.4版本开始的新规范，Variable和tensor合并后程序有所不同\n",
    "参考：[Variable和Tensor合并后，PyTorch的代码要怎么改](https://blog.csdn.net/dQCFKyQDXYm3F8rB0/article/details/80105285)\n",
    "从0.4版本开始程序框架如下：\n",
    "```python\n",
    "# torch.device object used throughout this script\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = MyRNN().to(device)\n",
    " \n",
    "# train\n",
    "total_loss = 0\n",
    "for input, target in train_loader:\n",
    "     input, target = input.to(device), target.to(device)\n",
    "     hidden = input.new_zeros(*h_shape) \n",
    "     # has the same device & dtype as `input`\n",
    "     ...  # get loss and optimize\n",
    "     total_loss += loss.item() # get Python number from 1-element Tensor\n",
    "\n",
    "# evaluate\n",
    "with torch.no_grad():          # operations inside don't track history\n",
    "     for input, target in test_loader:\n",
    "```\n",
    "\n",
    "其他修改部分：\n",
    "1. 使用`x.detach()`代替Variable中的`x.data`来修改数据，仅**原地**修改可改变原tensor\n",
    "2. 损失函数中使用`loss.item()`代替`loss.data[0]`来获取python数值\n",
    "3. 使用`tensor.type()`输出tensor的类型\n",
    "4. `torch.no_grad()`代替`volatile`标志位\n",
    "5. 可以创建零维向量，如`torch.tensor(2)`，更类似于`numpy.array()`函数\n",
    "```python\n",
    "print(torch.tensor(2))  # 只指定数据\n",
    "print(torch.Tensor(2))  # 既可以指定数据，也可以指定维度来随机数据\n",
    "# tensor(2)\n",
    "# tensor(1.00000e-45 *\n",
    "#      [ 1.4013,  0.0000])\n",
    "```\n",
    "\n",
    "注意：\n",
    "\n",
    "\n",
    "- 训练网络的时候把模型和数据都放到GPU上，测试的时候放到CPU上，因为cuda的变量无法直接转变为numpy的变量，测试会涉及到可视化等分析步骤，用numpy数据更佳\n",
    "- `model.to(device)`的方法不依赖设备更加通用，`model.cpu()`或`model.cuda()`转换模型的计算方式(变量同理)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "# 优先使用GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.weight_ih的两个权重: torch.Size([50, 20]) torch.Size([50, 50])\n",
      "  bias_ih的权重: torch.Size([50]) torch.Size([50])\n",
      "2.weight_hh的两个权重: torch.Size([50, 50]) torch.Size([50, 50])\n",
      "  bias_hh的权重: torch.Size([50]) torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "basic_rnn = nn.RNN(input_size=20, hidden_size=50, num_layers=2)\n",
    "print('1.weight_ih的两个权重:', basic_rnn.weight_ih_l0.shape, basic_rnn.weight_ih_l1.shape)\n",
    "print('  bias_ih的权重:', basic_rnn.bias_ih_l0.shape, basic_rnn.bias_ih_l1.shape)\n",
    "print('2.weight_hh的两个权重:', basic_rnn.weight_hh_l0.shape, basic_rnn.weight_hh_l1.shape)\n",
    "print('  bias_hh的权重:', basic_rnn.bias_hh_l0.shape, basic_rnn.bias_hh_l1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.RNN的输出output: torch.Size([100, 32, 50])\n",
      "2.RNN的输出隐层状态: torch.Size([2, 32, 50])\n"
     ]
    }
   ],
   "source": [
    "# 随机化初始输入xt和隐藏状态h0\n",
    "toy_input = torch.randn([100, 32, 20])            # [seq, batch, feature] \n",
    "h_0 = torch.randn([2, 32, 50])                    # [layers*direction, batch, hidden_size]\n",
    "toy_output, h_n = basic_rnn(toy_input, h_0)\n",
    "print('1.RNN的输出output:', toy_output.shape)      # [seq, batch, hidden_size*direction] \n",
    "print('2.RNN的输出隐层状态:', h_n.shape)           # [layers*direction, batch, hidden_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "小结：\n",
    "- 在一层的RNN中，如果是非双向循环的网络，一般只有一个记忆单元，所以隐藏状态的第一维度都是1，双向的网络为2，不同的层有各自的记忆单元，所以隐藏状态$h_t$的第一维度为：**layers*direction**，双向网络direction为2，普通的为1\n",
    "- 下面程序用于显示进度，以后可能会用，注意print函数中设置`end='\\r'`可以覆盖原输出\n",
    "```python\n",
    "def show_progress():\n",
    "    process = '<' + '.'*25 + '>'\n",
    "    for i in range(1, 26):\n",
    "        time.sleep(0.5)\n",
    "        process= process.replace('.', '=', 1)\n",
    "        print(process, end='\\r')\n",
    "    print('\\nfinished!')\n",
    "# 输出\n",
    "# <=========================>\n",
    "# finished!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 9.]) tensor([5., 9.])\n"
     ]
    }
   ],
   "source": [
    "# pytorch中的detach用法\n",
    "t1 = torch.FloatTensor([1., 2.])\n",
    "v1 = Variable(t1)\n",
    "t2 = torch.FloatTensor([2., 3.])\n",
    "v2 = Variable(t2)\n",
    "v3 = v1 + v2\n",
    "v3_detached = v3.detach()      # 只能原地修改\n",
    "v3_detached.data.add_(t1*2)    # 修改了 v3_detached Variable中 tensor 的值\n",
    "print(v3, v3_detached)         # v3 中tensor 的值也会改变"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 LSTM与GRU\n",
    "本质上与RNN一样，只是内部计算更复杂，参数更多\n",
    "- LSTM做了4次类似标准RNN的运算，所以参数是标准RNN的4倍，隐藏状态为$h_0$和$c_0$，维度均是**(layers*direction, batch, hidden_size)**，direction：单向为1，双向为2\n",
    "- GRU参数是标准RNN的3倍，隐藏状态只有$h_0$，维度同上\n",
    "- LSTM与GRU的定义方法基本与标准RNN的一样，但无nonlinearity参数，其他可参考标准RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.weight_ih的两个权重: torch.Size([200, 20]) torch.Size([200, 50])\n",
      "  bias_ih的权重: torch.Size([200]) torch.Size([200])\n",
      "2.weight_hh的两个权重: torch.Size([200, 50]) torch.Size([200, 50])\n",
      "  bias_hh的权重: torch.Size([200]) torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "# 1. 定义lstm\n",
    "# 参数维度4翻倍：[output_size*4, input_size]\n",
    "lstm = nn.LSTM(input_size=20, hidden_size=50, num_layers=2)\n",
    "print('1.weight_ih的两个权重:', lstm.weight_ih_l0.shape, lstm.weight_ih_l1.shape)\n",
    "print('  bias_ih的权重:', lstm.bias_ih_l0.shape, lstm.bias_ih_l1.shape)\n",
    "print('2.weight_hh的两个权重:', lstm.weight_hh_l0.shape, lstm.weight_hh_l1.shape)\n",
    "print('  bias_hh的权重:', lstm.bias_hh_l0.shape, lstm.bias_hh_l1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 32, 50])\n",
      "torch.Size([2, 32, 50])\n",
      "torch.Size([2, 32, 50])\n"
     ]
    }
   ],
   "source": [
    "toy_input = torch.randn([100, 32, 20])            # [seq, batch, feature] \n",
    "lstm_out, (h_n, c_n) = lstm(toy_input)\n",
    "print(lstm_out.shape)        # [seq, batch, hidden*direction]\n",
    "print(h_n.shape)             # [layers*direction, batch, hidden]\n",
    "print(c_n.shape)             # [layers*direction, batch, hidden]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.weight_ih的两个权重: torch.Size([150, 20]) torch.Size([150, 50])\n",
      "  bias_ih的权重: torch.Size([150]) torch.Size([150])\n",
      "2.weight_hh的两个权重: torch.Size([150, 50]) torch.Size([150, 50])\n",
      "  bias_hh的权重: torch.Size([150]) torch.Size([150])\n"
     ]
    }
   ],
   "source": [
    "# 2. 定义GRU\n",
    "gru = nn.GRU(input_size=20, hidden_size=50, num_layers=2)\n",
    "print('1.weight_ih的两个权重:', gru.weight_ih_l0.shape, gru.weight_ih_l1.shape)\n",
    "print('  bias_ih的权重:', gru.bias_ih_l0.shape, gru.bias_ih_l1.shape)\n",
    "print('2.weight_hh的两个权重:', gru.weight_hh_l0.shape, gru.weight_hh_l1.shape)\n",
    "print('  bias_hh的权重:', gru.bias_hh_l0.shape, gru.bias_hh_l1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 32, 50])\n",
      "torch.Size([2, 32, 50])\n"
     ]
    }
   ],
   "source": [
    "gru_out, h_n = gru(toy_input)\n",
    "print(gru_out.shape)         # [seq, batch, hidden*direction]\n",
    "print(h_n.shape)             # [layers*direction, batch, hidden]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "小结:\n",
    "- nn.RNN、nn.LSTM和nn.GRU定义的是完整序列的网络，而RNNCell、LSTMCell和GRUCell定义单步的网络，即只是序列中的一步，循环神经网络的一个循环"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 循环神经网络实例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 图像分类\n",
    "这里使用MNIST数据集，该数据集中图像是28*28的，可以将图像看作长为28的序列，序列中每个元素特征维度为28，将图像序列化后可以用RNN来处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.导入数据\n",
    "data_tf =transforms.Compose([\n",
    "    transforms.ToTensor(),                   # 将图像转换为[0~1]的tensor\n",
    "    transforms.Normalize([0.5], [0.5])       # 标准化到[-1,1]\n",
    "])\n",
    "# 导入MNIST数据集\n",
    "train_datasets = datasets.MNIST(root='./data/MNIST', train=True, transform=data_tf, download=False)\n",
    "test_datasets = datasets.MNIST(root='./data/MNIST', train=False, transform=data_tf)\n",
    "\n",
    "# [b,28,28] 可以看作 [batch, seq, feature]的序列化数据\n",
    "train_loader = DataLoader(train_datasets, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_datasets, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23b67391ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 显示数据\n",
    "def show():\n",
    "    labels = test_datasets.test_labels.numpy()  # 没有经过transforms的数据\n",
    "    data = test_datasets.test_data.numpy()\n",
    "    # np.where获得结果:(array([1,...], dtype=int64), )，所以使用[0][index]获取元素\n",
    "    sample_index = [np.where(labels==i)[0][0] for i in range(10)]\n",
    "    sample_data = data[sample_index]\n",
    "    for i in range(10):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(sample_data[i], cmap='gray')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建序列化图像的生成器，为训练模型提供批次数据(该函数不是必须的)\n",
    "# [b,28,28] -> [b, seq, feature]\n",
    "def generator(batch_size=32, train=True, shuffle=True):\n",
    "    datasets = train_datasets if train else test_datasets\n",
    "    # 先生成批次的数据\n",
    "    loader = DataLoader(datasets, batch_size=batch_size, shuffle=shuffle, num_workers=4)\n",
    "    for data in loader:\n",
    "       yield data[0], data[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.定义模型\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, n_layers, n_classes):\n",
    "        super().__init__() \n",
    "        self.n_layers = n_layers       # RNN层数\n",
    "        self.n_classes = n_classes     # 输出类别数\n",
    "        self.hidden_dim = hidden_dim   # 隐藏状态特征数\n",
    "        self.lstm = nn.LSTM(input_size=in_dim, hidden_size=hidden_dim, \n",
    "                            num_layers=n_layers, batch_first=True)\n",
    "        # batch_first 使输入为 [batch, seq, input_dim]\n",
    "        self.classifier = nn.Linear(hidden_dim, n_classes)   # 分类\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)     # 传入网络 get [batch,seq,hidden]\n",
    "        out = lstm_out[:, -1, :]       # 获取序列的最后输出 get [batch,hidden]\n",
    "        # 获取序列最后时间点的输出，seq和时间序列对应\n",
    "#         print(out.shape)             # get [batch, hidden]\n",
    "        out = self.classifier(out)     # get [batch, n_classes] \n",
    "#         print(out.shape)\n",
    "        return out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.RNN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义损失函数及优化函数\n",
    "rnn_model = RNN(28,256,2,10)           # 创建模型\n",
    "criterion = nn.CrossEntropyLoss()      # 用于标签不是one-hot的数据\n",
    "optimizer = optim.Adam(rnn_model.parameters(), lr=1e-2)\n",
    "type(rnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Epoch 1\n",
      "Batches 0 loss 2.3053\n",
      "Batches 100 loss 1.0990\n",
      "Batches 200 loss 0.8368\n",
      "Batches 300 loss 0.2619\n",
      "Batches 400 loss 0.3684\n",
      "Batches 500 loss 0.5868\n",
      "Batches 600 loss 0.7592\n",
      "Batches 700 loss 0.3227\n",
      "Batches 800 loss 0.4057\n",
      "Batches 900 loss 0.1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# 3.训练模型\n",
    "batch_size = 32      # 定义batch_size\n",
    "epochs = 1           # 定义epoch最大次数\n",
    "max_batches = np.ceil(len(train_datasets) / batch_size)*epochs\n",
    "# print(max_batches)\n",
    "\n",
    "def train(model, batch_size, epochs, save_path='./model'):\n",
    "    num_batches = 0                                    # 记录batches的数目\n",
    "    train_loader = DataLoader(train_datasets, batch_size=batch_size, shuffle=True,\n",
    "                             num_workers=4) \n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        print('-'*20)\n",
    "        print('Epoch {}'.format(epoch+1))\n",
    "        for data in train_loader: \n",
    "            # 将变量及模型放到GPU上\n",
    "            x_train, y_train = data   # x维度 [b,1,28,28]\n",
    "            x_train = x_train[:,0]    # x维度 [b,28,28]\n",
    "            x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "#             print(x_train.shape)\n",
    "            # forward + backward + optimizer    \n",
    "            out = model(x_train)                  # 计算输出\n",
    "            loss = criterion(out, y_train)        # 计算损失函数\n",
    "            print_loss = loss.item()\n",
    "            optimizer.zero_grad()                 # 梯度归零\n",
    "            loss.backward()                       # 反向传播\n",
    "            optimizer.step()                      # 更新参数\n",
    "#             print(num_batches)\n",
    "                        \n",
    "            if (num_batches) % 100 == 0:\n",
    "#                 print(type(model))\n",
    "                print('Batches {} loss {:.4f}'.format(num_batches, print_loss))\n",
    "            num_batches += 1\n",
    "            if num_batches == 1000:               # 为了快速验证程序，中断训练\n",
    "                break\n",
    "    # 存储路径        \n",
    "    save_path = os.path.join(save_path, 'rnn_{}.pth'.format(num_batches))   \n",
    "    torch.save(model, save_path)                #存储路径\n",
    "     \n",
    "train(rnn_model, batch_size, epochs)         # 训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Test Loss: 0.332930, ACC: 0.906250\n",
      "Epoch: 20 Test Loss: 0.530187, ACC: 0.875000\n",
      "Epoch: 30 Test Loss: 0.382257, ACC: 0.875000\n",
      "Epoch: 40 Test Loss: 0.368515, ACC: 0.875000\n",
      "Epoch: 50 Test Loss: 0.474718, ACC: 0.781250\n",
      "Epoch: 60 Test Loss: 0.434582, ACC: 0.875000\n",
      "Epoch: 70 Test Loss: 0.398774, ACC: 0.875000\n",
      "Epoch: 80 Test Loss: 0.546223, ACC: 0.875000\n",
      "Epoch: 90 Test Loss: 0.303690, ACC: 0.875000\n",
      "Epoch: 100 Test Loss: 0.079886, ACC: 1.000000\n",
      "Epoch: 110 Test Loss: 0.376336, ACC: 0.843750\n",
      "Epoch: 120 Test Loss: 0.515528, ACC: 0.843750\n",
      "Epoch: 130 Test Loss: 0.701372, ACC: 0.750000\n",
      "Epoch: 140 Test Loss: 0.368030, ACC: 0.843750\n",
      "Epoch: 150 Test Loss: 0.069468, ACC: 1.000000\n",
      "Epoch: 160 Test Loss: 0.168973, ACC: 0.906250\n",
      "Epoch: 170 Test Loss: 0.042365, ACC: 1.000000\n",
      "Epoch: 180 Test Loss: 0.660746, ACC: 0.843750\n",
      "Epoch: 190 Test Loss: 0.519290, ACC: 0.875000\n",
      "Epoch: 200 Test Loss: 0.189386, ACC: 0.937500\n",
      "Epoch: 210 Test Loss: 0.319277, ACC: 0.906250\n",
      "Epoch: 220 Test Loss: 0.147183, ACC: 0.968750\n",
      "Epoch: 230 Test Loss: 0.150100, ACC: 0.937500\n",
      "Epoch: 240 Test Loss: 0.220129, ACC: 0.937500\n",
      "Epoch: 250 Test Loss: 0.401125, ACC: 0.875000\n",
      "Epoch: 260 Test Loss: 0.423263, ACC: 0.843750\n",
      "Epoch: 270 Test Loss: 0.309275, ACC: 0.906250\n",
      "Epoch: 280 Test Loss: 0.066944, ACC: 1.000000\n",
      "Epoch: 290 Test Loss: 0.084740, ACC: 1.000000\n",
      "Epoch: 300 Test Loss: 0.232688, ACC: 0.875000\n",
      "Epoch: 310 Test Loss: 0.327496, ACC: 0.875000\n",
      "----------Test Done!----------\n",
      "Epoch: 313 Total_Loss: 0.365389 Total_ACC: 0.887000\n"
     ]
    }
   ],
   "source": [
    "# 5.评价模型的性能\n",
    "def test(model, batch_size=32):\n",
    "    test_loader = DataLoader(test_datasets, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model.eval()      # 将模型转换为测试状态\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    test_epoch = 0 \n",
    "    for data in test_loader:\n",
    "        eval_loss = 0\n",
    "        eval_acc = 0\n",
    "        img, label = data      # 获取测试数据\n",
    "        img = img[:,0]\n",
    "    #     print(img.shape)\n",
    "        # 由于测试状态下不需方向传播，所以可以释放缓存\n",
    "        with torch.no_grad():\n",
    "\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            out = model(img)     # 计算图像的标签 [img.size(0), 10]\n",
    "            loss = criterion(out, label)\n",
    "            eval_loss += loss.data* label.size(0)   # 计算该批次的总损失\n",
    "            _, pred = torch.max(out, 1)          # 在一行内按列比大小得[64,1],tenso为[64]\n",
    "        #     print(_, pred.shape)\n",
    "            num_correct = (pred == label).sum()\n",
    "            eval_acc += num_correct.data\n",
    "        #     print(eval_acc)    \n",
    "            total_loss += eval_loss    # 累计所有批次数据的损失和准确率\n",
    "            total_acc  += eval_acc\n",
    "            if (test_epoch + 1) % 10 == 0:\n",
    "                batch_loss  = (eval_loss / img.size(0))        # 计算该批次的损失\n",
    "                batch_acc   = (eval_acc.float() / img.size(0)) # 计算该批次的准确率\n",
    "                print('Epoch: {} Test Loss: {:.6f}, ACC: {:.6f}'.format(test_epoch+1, batch_loss, batch_acc))\n",
    "            test_epoch += 1\n",
    "    print('----------Test Done!----------')\n",
    "    print('Epoch: {} Total_Loss: {:.6f} Total_ACC: {:.6f}'.format(\\\n",
    "          test_epoch, total_loss/len(test_datasets), float(total_acc)/len(test_datasets)))\n",
    "save_model = torch.load('./model/rnn_1000.pth')\n",
    "save_model.to(device)\n",
    "test(save_model)         # 评估模型性能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 预测时间序列(回归)\n",
    "循环神经网络具有记忆单元，所以可以预测时间序列\n",
    "\n",
    "这里使用sin曲线预测cos曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.设定超参数 \n",
    "time_step = 10     # rnn的时间步长，即seq长度\n",
    "input_size = 1     # rnn的输入维度\n",
    "lr = 1e-2          # 学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x253defd2ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# 2.显示数据，绘制sin和cos曲线\n",
    "def show():\n",
    "    x = np.linspace(0, np.pi*2, 100, dtype=np.float32)  # 定义横轴的100个数据\n",
    "    y_sin = np.sin(x)     # 计算纵轴的数据\n",
    "    y_cos = np.cos(x)\n",
    "    plt.plot(x, y_sin, 'r-', label='input (sinx)')\n",
    "    plt.plot(x, y_cos, 'b-', label='target (cosx)')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.定义网络\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim=1):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=in_dim,          # 网络的输入维度为1\n",
    "            hidden_size= hidden_dim,    # 隐藏单元的特征数(维度)\n",
    "            num_layers = 1,             # 网络层数\n",
    "            batch_first = True          # (batch, time_step, input_size)\n",
    "        )\n",
    "        self.dense = nn.Linear(hidden_dim, out_dim)  # 网络输出维度也是1 \n",
    "    \n",
    "    def forward(self, x, h_state):\n",
    "        # x: (batch, time_step, in_dim)\n",
    "        # rnn_out: (batch, time_step, hidden_dim*1)  time_step即seq长度\n",
    "        # h_state: (num_layers*1, batch, hidden_dim)\n",
    "        \n",
    "        # rnn_out是time_step上的整个输出，即seq序列上的整个输出\n",
    "        # 而这里的 h_state却是最后一个时间点(seq序列的最后一个)的输出\n",
    "        rnn_out, h_state = self.rnn(x, h_state)\n",
    "#         print(rnn_out.size(), h_state.shape)\n",
    "        \n",
    "        # 保存所有时间点的预测值\n",
    "        total_out = []\n",
    "        for step in range(rnn_out.size(1)):   # 按照time_step访问数据\n",
    "            step_out = rnn_out[:, step, :]    # 获取当前time的输出 [batch, hidden]\n",
    "            dense_out = self.dense(step_out)  # 通过全连接获得当前输出值 [batch, 1]\n",
    "            total_out.append(dense_out)\n",
    "#         print(total_out)\n",
    "        out = torch.stack(total_out, dim=1)   # 第2维度叠加 [batch, time_step, in_dim]\n",
    "#         print(out.shape)\n",
    "        return out, h_state\n",
    "    \n",
    "#     # 使用向量化的方式来代替循环，提高计算效率\n",
    "#     def forward(self, x, h_state):\n",
    "#         rnn_out, h_state = self.rnn(x, h_state) \n",
    "# #       print(rnn_out.shape, h_state.shape)\n",
    "#         rnn_out_reshaped = torch.reshape(rnn_out, [-1, self.hidden_dim]) # get [*,hidden]\n",
    "# #       print(rnn_out_reshaped.shape)\n",
    "# #       rnn_out_reshaped = rnn_out.view(-1, self.hidden_dim)    # there is a bug!!!!!\n",
    "       \n",
    "#         dense_out = self.dense(rnn_out_reshaped)                # get [*,1]\n",
    "#         final_out = dense_out.view(-1, time_step, self.out_dim) # get [batch, tim_step, out_dim]\n",
    "#         return final_out, h_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Epoch 100 loss 0.0007\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "# 4.定义损失函数、优化函数\n",
    "rnn = RNN(in_dim=1, hidden_dim=6)              # 创建RNN模型\n",
    "criterion = nn.MSELoss()                         # 回归任务，使用均方差损失\n",
    "optimizer = optim.Adam(rnn.parameters(), lr=lr)  # Adam优化\n",
    "epochs = 100                                     # 使用数据训练几轮\n",
    "h_state = None                                   # 开始的状态h_0设置为0\n",
    "\n",
    "plt.figure(1, figsize=(12, 5))\n",
    "plt.ion()\n",
    "# 训练模型\n",
    "def train(model):\n",
    "    global h_state\n",
    "    for epoch in range(epochs):\n",
    "        start, end = map(lambda x:x*np.pi, [epoch, epoch+1])   # [n*pi, (n+1)*pi]\n",
    "        steps = np.linspace(start, end, time_step, dtype=np.float32)  # 取10个数据\n",
    "        x_np = np.sin(steps)   # 这里用sinx预测cosx\n",
    "        y_np = np.cos(steps)\n",
    "        \n",
    "        # 将数据转换到rnn可输入的维度\n",
    "        # 定义函数扩展维度，并转换为tensor\n",
    "        unsqueeze = lambda x: torch.from_numpy(x[np.newaxis, :, np.newaxis])\n",
    "        x, y = map(unsqueeze, [x_np, y_np])   # 扩展x,y维度 [batch, time_step, in_dim]      \n",
    "        \n",
    "        # rnn 对于每个 step 的 prediction, 还有最后一个 step 的 h_state\n",
    "        prediction , h_state= model(x, h_state)\n",
    "        # 该步骤很重要，重新包装隐藏状态，断开与上次迭代的连接!!!\n",
    "        h_state = h_state.data \n",
    "        \n",
    "        loss = criterion(prediction, y)      \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 弹出窗口显示动态图\n",
    "        plt.plot(steps, y_np.flatten(), 'r-')\n",
    "        plt.plot(steps, prediction.data.numpy().flatten(), 'b-')\n",
    "        plt.draw(); plt.pause(0.05)\n",
    "    print('Epoch {} loss {:.4f}'.format(epoch+1, loss.item()))          \n",
    "    plt.ioff()\n",
    "    plt.show()\n",
    "                       \n",
    "train(rnn)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "小结:\n",
    "- jupyter中显示动态图的方法\n",
    "```python\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "display.clear_output(wait=True)\n",
    "```\n",
    "经过“画图=>清理=>画图”循环来动态显示图片\n",
    "- 在RNN做分类时，不同批次的数据是不联系的，所以不需要保存该批次的`hidden_state`，但在RNN做回归时，整个训练集是时间序列，所以按顺序进行训练的批次是有关系的，需要保存上一批次的`hidden_state`，其中`h_state = h_state.data`一句把上一次的状态保存以备下次使用 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
