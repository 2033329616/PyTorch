{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1 简单的卷积网络\n",
    " ### 1.1 卷积模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (layer1): Sequential(\n",
      "    (conv1): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    (relu1): ReLU(inplace)\n",
      "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu2): ReLU(inplace)\n",
      "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu3): ReLU(inplace)\n",
      "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (fc_relu1): ReLU(inplace)\n",
      "    (fc2): Linear(in_features=512, out_features=64, bias=True)\n",
      "    (fc2_relu2): ReLU(inplace)\n",
      "    (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 定义简单的卷积网络模型\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):            # 定义网络结构\n",
    "        super().__init__()         # 输入 [batch_size,3,32,32] 3表示深度\n",
    "        layer1 = nn.Sequential()   # 叠加第1个网络层，卷积层\n",
    "        # (in_channels, out_channels, kernel_size,stride,padding)\n",
    "        layer1.add_module('conv1', nn.Conv2d(32, 3, 1, padding=1))\n",
    "        # get [batch_size, 32, 32, 32]\n",
    "        layer1.add_module('relu1', nn.ReLU(True))\n",
    "        layer1.add_module('pool1', nn.MaxPool2d(2,2))\n",
    "        # get [batch_size, 32, 16, 16]\n",
    "        self.layer1 = layer1\n",
    "        \n",
    "        layer2 = nn.Sequential()   # 定义第2个网络层\n",
    "        layer2.add_module('conv2', nn.Conv2d(32, 64, 3, 1, padding=1))\n",
    "        # get [batch_size, 64, 16, 16] \n",
    "        layer2.add_module('relu2', nn.ReLU(True))\n",
    "        layer2.add_module('pool2', nn.MaxPool2d(2,2))\n",
    "        # get [batch_size, 64, 8, 8]\n",
    "        self.layer2 = layer2\n",
    "        \n",
    "        layer3 = nn.Sequential()   # 定义第3个网络层\n",
    "        layer3.add_module('conv3', nn.Conv2d(64, 128, 3, 1, padding=1))\n",
    "        # get [batch_size, 128, 8, 8]\n",
    "        layer3.add_module('relu3', nn.ReLU(True))\n",
    "        layer3.add_module('pool3', nn.MaxPool2d(2,2))\n",
    "        # get [batch_size, 128, 4, 4]\n",
    "        self.layer3 = layer3\n",
    "        \n",
    "        layer4 = nn.Sequential()   # 定义第4个网络层，全连接层\n",
    "        layer4.add_module('fc1', nn.Linear(128*4*4, 512))\n",
    "        # get [batch_size, 512]\n",
    "        layer4.add_module('fc_relu1', nn.ReLU(True))\n",
    "        layer4.add_module('fc2', nn.Linear(512, 64))\n",
    "        # get [batch_size, 64]\n",
    "        layer4.add_module('fc2_relu2', nn.ReLU(True))\n",
    "        layer4.add_module('fc3', nn.Linear(64, 10))\n",
    "        # get [batch_size, 10]\n",
    "        self.layer4 = layer4\n",
    "    def forward(self, x):\n",
    "        conv1 = self.layer1(x)   # 前3层为卷积层\n",
    "        conv2 = self.layer2(conv1)\n",
    "        conv3 = self.layer3(conv2)\n",
    "        # 注意：全连接前要把数据的维度将为两维，-1维度长*宽*深度\n",
    "        fc_input = conv3.view(conv3.size(0), -1)  # reshape为 [batch_size, -1]\n",
    "        fc_out = self.layer4(fc_input)\n",
    "        return fc_out\n",
    "model = SimpleCNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "小结:\n",
    "- 模型层顺序：CNN+BN+ReLU+Pooling，先激活再池化;FC+ReLU+Dropout\n",
    "- 输出层不用激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 提取模型的层结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|nn.Module属性|功能|实例|\n",
    "|-|-|-|\n",
    "|children()|返回下一级迭代器|self.layer1|\n",
    "|modules()|返回所有模块迭代器|self.layer1.conv1|\n",
    "|named_children()|返回模块的名称|其他功能同上|\n",
    "|named_modules()|返回模块的名称|其他功能同上|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1)) (1, 1) 3\n",
      "-----\n",
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (3, 3) 64\n",
      "-----\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (3, 3) 128\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# 提取已有模型中的结构\n",
    "new_model = nn.Sequential(*list(model.children())[:2])   # *代表使用可变参数\n",
    "# print(new_model)\n",
    "# list(model.children())[0]\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        print(m, m.kernel_size, m.out_channels)\n",
    "        print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('layer1.conv1', Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1)))\n",
      "--------------------------------------------------\n",
      "('layer2.conv2', Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n",
      "--------------------------------------------------\n",
      "('layer3.conv3', Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n",
      "--------------------------------------------------\n",
      "1.新网络的结构:\n",
      "Sequential(\n",
      "  (conv1): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 提取模型中所有的卷积层\n",
    "conv_model = nn.Sequential()\n",
    "for layer in model.named_modules():    # layer[0]层名称, layer[1]层类型\n",
    "#     print(layer)\n",
    "\n",
    "    if isinstance(layer[1], nn.Conv2d):  \n",
    "        print(layer)\n",
    "        print('-'*50)\n",
    "        conv_model.add_module(layer[0].split('.')[-1], layer[1])\n",
    "print('1.新网络的结构:')\n",
    "print(conv_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 提取参数及初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|nn.Module属性|功能|\n",
    "|-|-|\n",
    "|parameters()|返回全部参数的迭代器|\n",
    "|named_parameters()|返回模块的名称，其他功能同上|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.conv1.weight\n",
      "torch.Size([3, 32, 1, 1])\n",
      "--------------------------------------------------\n",
      "layer1.conv1.bias\n",
      "torch.Size([3])\n",
      "--------------------------------------------------\n",
      "layer2.conv2.weight\n",
      "torch.Size([64, 32, 3, 3])\n",
      "--------------------------------------------------\n",
      "layer2.conv2.bias\n",
      "torch.Size([64])\n",
      "--------------------------------------------------\n",
      "layer3.conv3.weight\n",
      "torch.Size([128, 64, 3, 3])\n",
      "--------------------------------------------------\n",
      "layer3.conv3.bias\n",
      "torch.Size([128])\n",
      "--------------------------------------------------\n",
      "layer4.fc1.weight\n",
      "torch.Size([512, 2048])\n",
      "--------------------------------------------------\n",
      "layer4.fc1.bias\n",
      "torch.Size([512])\n",
      "--------------------------------------------------\n",
      "layer4.fc2.weight\n",
      "torch.Size([64, 512])\n",
      "--------------------------------------------------\n",
      "layer4.fc2.bias\n",
      "torch.Size([64])\n",
      "--------------------------------------------------\n",
      "layer4.fc3.weight\n",
      "torch.Size([10, 64])\n",
      "--------------------------------------------------\n",
      "layer4.fc3.bias\n",
      "torch.Size([10])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 提取模型的所有参数\n",
    "for param in model.named_parameters():\n",
    "    # param[0]:层名称.weight/bias  param[1]:参数值，权重是Variable\n",
    "    print(param[0])\n",
    "    print((param[1]).data.shape)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取参数并初始化????????\n",
    "init = nn.init\n",
    "for m in model.modules():  # 访问所有模块\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.normal_(m.weight.data)\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        m.weight.data.normal_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 卷积神经网络实例\n",
    "### 2.1 LeNet网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv层参数设置：[in_channels,out_channels,kernel_size,stride,padding]\n",
    "$$W_{conv} = \\frac{W_{input}-kernel\\_size+2*padding}{stride}+1$$\n",
    "\n",
    "maxpooling层参数设置：[kernel_size,stride,padding]\n",
    "\n",
    "fc层参数设置：[in_channels,out_channels]\n",
    "\n",
    "- 表格参数设置：[卷积核数/宽/高/深度] [池化宽/高] s:stride p:padding\n",
    "\n",
    "|结构|参数设置|数据维度|\n",
    "|-|-|-|\n",
    "|input||[batch_size,3,32,32]|\n",
    "|conv1|$[6\\times5\\times5\\times3]$<br>s=1 p=0|[batch_size,6,28,28]|\n",
    "|pool1|$[2\\times2]$<br>s=2 p=0|[batch_size,6,14,14]|\n",
    "|conv2|$[16\\times5\\times5\\times6]$<br>s=1 p=0 |[batch_size,16,10,10]|\n",
    "|pool2|$[2\\times2]$<br>s=2 p=0|[batch_size,16,5,5]|\n",
    "|fc1|$[(16*5*5)\\times120]$|[batch_size,120]|\n",
    "|fc2|$[120\\times84]$|[batch_size,84]|\n",
    "|fc3|$[84\\times10]$|[batch_size,10]|\n",
    "|--------|-------------------------------|--------------------------------|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络结构\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()  # 输入维度[b,3,32,32]\n",
    "        \n",
    "        # 第一个卷积、池化模块\n",
    "        layer1 = nn.Sequential()\n",
    "        layer1.add_module('conv1', nn.Conv2d(3,6,5,1,padding=0))\n",
    "        # get [b,6,28,28]\n",
    "        layer1.add_module('pool1', nn.MaxPool2d(2,2))\n",
    "        # get [b,6,14,14]\n",
    "        self.layer1 = layer1\n",
    "        \n",
    "        # 第二个卷积、池化模块\n",
    "        layer2 = nn.Sequential()\n",
    "        layer2.add_module('conv2', nn.Conv2d(6,16,5,padding=0))\n",
    "        # get [b,16,10,10]\n",
    "        layer2.add_module('pool2', nn.MaxPool2d(2,2))\n",
    "        # get [b,16,5,5]\n",
    "        self.layer2 = layer2\n",
    "        \n",
    "        # 第三个全连接模块\n",
    "        # 先将卷积的feature map reshape为[b,16*5*5]的形状\n",
    "        layer3 = nn.Sequential()\n",
    "        layer3.add_module('fc1', nn.Linear(16*5*5, 120))\n",
    "        # get [b,120]\n",
    "        layer3.add_module('fc2', nn.Linear(120, 84))\n",
    "        # get [b, 84]\n",
    "        layer3.add_module('fc3', nn.Linear(84, 10))\n",
    "        # get [b, 10]\n",
    "        self.layer3 = layer3\n",
    "    def forward(self, x):\n",
    "        conv1 = self.layer1(x)\n",
    "        conv2 = self.layer2(conv1)\n",
    "        fc_input = conv2.view(conv2.size(0), -1)\n",
    "        fc_output = self.layer3(fc_input)\n",
    "        return fc_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.随机输入的数据: torch.Size([1, 3, 32, 32])\n",
      "2.模型输出: torch.Size([1, 10])\n",
      "Wall time: 21 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LeNet_model = LeNet()\n",
    "data_random = torch.Tensor(range(3*32*32))\n",
    "input = data_random.reshape([1,3,32,32])\n",
    "print('1.随机输入的数据:', input.shape)\n",
    "output = LeNet_model(Variable(input))\n",
    "print('2.模型输出:', output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 AlexNet\n",
    "2012年ILSVRC冠军网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表格参数设置(与函数对应)：\n",
    "- 卷积 [in_channels,out_channels,kernel_size,stride,padding]\n",
    "\n",
    "- 池化 [kernel_size,stride,padding]\n",
    "\n",
    "|结构|参数设置|数据维度|\n",
    "|-|-|-|\n",
    "|input||[batch_size,3,227,227]|\n",
    "|conv1|[3,96,11,4,padding=0]  |[batch_size,96,55,55]|\n",
    "|conv2|[96,256,5,1,padding=2] |[batch_size,256,55,55]|\n",
    "|MaxPool|[3,2]                |[batch_size,256,27,27]|\n",
    "|conv3|[256,384,3,1,padding=1]|[batch_size,384,27,27]|\n",
    "|MaxPool|[3,2]                |[batch_size,384,13,13]|\n",
    "|conv4|[384,384,3,1,padding=1]|[batch_size,384,13,13]|\n",
    "|conv5|[384,256,3,1,padding=1]|[batch_size,256,13,13]|\n",
    "|MaxPool|[3,2]                |[batch_size,256,6,6]|\n",
    "|dense1|[256\\*6\\*6,4096]      |[batch_size,4096]|\n",
    "|dense2|[4096,4096]           |[batch_size,4096]|\n",
    "|dense3|[4096,1000]           |[batch_size,1000]|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义AlexNet网络\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()    # 输入 [b,3,227,227]\n",
    "        # 定义第1个卷积层\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, 11, 4, 0),    # get [b,96,55,55]\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        # 定义第2个卷积层\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),   # get [b,256,55,55]\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(3,2)              # get [b,256,27,27]\n",
    "        )\n",
    "        # 定义第3个卷积层\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),  # get [b,384,27,27]\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(3, 2)             # get [b,384,13,13]\n",
    "        )\n",
    "        # 定义第4个卷积层\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),  # get [b,384,13,13]\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        # 定义第5个卷积层\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),  # get [b,256,13,13]\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(3, 2)             # get [b,256,6,6]\n",
    "        )\n",
    "        # 定义6,7,8层全连接层\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(256*6*6, 4096),      # get [b,4096]，需先reshape[b,9216]\n",
    "            nn\n",
    "            .ReLU(True),\n",
    "            nn.Dropout(0.5),               # dropout减少正则化\n",
    "            nn.Linear(4096, 4096),         # get [b,4096]\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 1000)          # get [b,1000]\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv2_out = self.conv2(conv1_out)\n",
    "        conv3_out = self.conv3(conv2_out)\n",
    "        conv4_out = self.conv4(conv3_out)\n",
    "        conv5_out = self.conv5(conv4_out)\n",
    "        dense_input = conv5_out.view(conv5_out.size(0), -1)  # reshape 为一维\n",
    "        out = self.dense(dense_input)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.随机输入的数据: torch.Size([1, 3, 227, 227])\n",
      "2.模型输出: torch.Size([1, 1000])\n",
      "Wall time: 563 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "AlexNet_model = AlexNet()\n",
    "# print(model)\n",
    "data_random = torch.Tensor(range(3*227*227))\n",
    "input = data_random.reshape([1,3,227,227])\n",
    "print('1.随机输入的数据:', input.shape)\n",
    "output = AlexNet_model(Variable(input))\n",
    "print('2.模型输出:', output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 VGGNet\n",
    "ImageNet 2014年亚军，使用小滤波器和更深层网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16网络表格参数设置(与函数对应)：\n",
    "- 卷积 [in_channels,out_channels,kernel_size,stride,padding]\n",
    "\n",
    "- 池化 [kernel_size,stride,padding]\n",
    "\n",
    "|结构|参数设置|数据维度|\n",
    "|-|-|-|\n",
    "|input||[batch_size,3,224,224]|\n",
    "|conv1|[3,64,3,1,padding=1]   |[batch_size,64,224,224]|\n",
    "|conv2|[64,64,3,1,padding=1]  |[batch_size,64,224,224]|\n",
    "|MaxPool|[2,2]                |[batch_size,64,112,112]|\n",
    "|conv3|[64,128,3,1,padding=1] |[batch_size,128,112,112]|\n",
    "|conv4|[128,128,3,1,padding=1]|[batch_size,128,112,112]|\n",
    "|MaxPool|[2,2]                |[batch_size,128,56,56]|\n",
    "|conv5|[128,256,3,1,padding=1]|[batch_size,256,56,56]|\n",
    "|conv6|[256,256,3,1,padding=1]|[batch_size,256,56,56]|\n",
    "|conv7|[256,256,3,1,padding=1]|[batch_size,256,56,56]|\n",
    "|MaxPool|[2,2]                |[batch_size,256,28,28]|\n",
    "|conv8|[256,512,3,1,padding=1]|[batch_size,512,28,28]|\n",
    "|conv9|[512,512,3,1,padding=1]|[batch_size,512,28,28]|\n",
    "|conv10|[512,512,3,1,padding=1]|[batch_size,512,28,28]|\n",
    "|MaxPool|[2,2]                 |[batch_size,512,14,14]|\n",
    "|conv11|[512,512,3,1,padding=1]|[batch_size,512,14,14]|\n",
    "|conv12|[512,512,3,1,padding=1]|[batch_size,512,14,14]|\n",
    "|conv13|[512,512,3,1,padding=1]|[batch_size,512,14,14]|\n",
    "|MaxPool|[2,2]                |[batch_size,512,7,7]|\n",
    "|dense1|[512\\*7\\*7,4096]      |[batch_size,4096]|\n",
    "|dense2|[4096,4096]           |[batch_size,4096]|\n",
    "|dense3|[4096,1000]           |[batch_size,1000]|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "小结:\n",
    "- VGGNet中使用$3\\times3$的卷积核，stride=1，padding=1，所以卷积完后图像的宽和高不变，仅通道数改变\n",
    "- VGGNet中使用$2\\times2$的最大池化核,stride=2，所以池化后图像的宽和高会减为一半，但通道数不会改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义VGG-16的网络结构\n",
    "# 方法一，笨办法，逐层定义\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()                 # 输入 [b,3,224,224]\n",
    "        # conv参数 [in_channels,out_channels,kernel_size,stride,padding]\n",
    "        # maxpool参数 [kernel_size, stride]\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),     # get [b,64,224,224]\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 64, 3, 1, 1),    # get [b,64,224,224]\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.MaxPool2d(2, 2),            # get [b,64,112,112]\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, 1, 1),   # get [b,128,112,112]\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 128, 3, 1, 1),  # get [b,128,112,112]\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),            # get [b,128,56,56]\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, 1, 1),  # get [b,256,56,56]\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),  # get [b,256,56,56]\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),  # get [b,256,56,56]\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),            # get [b,256,28,28]\n",
    "            \n",
    "            nn.Conv2d(256, 512, 3, 1, 1),  # get [b,512,28,28]\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),  # get [b,512,28,28]\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),  # get [b,512,28,28]\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),            # get [b,512,14,14]\n",
    "            \n",
    "            nn.Conv2d(512, 512, 3, 1, 1),  # get [b,512,14,14]\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),  # get [b,512,14,14]\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),  # get [b,512,14,14]\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2)            # get [b,512,7,7]    \n",
    "        )\n",
    "        # 将卷积层reshape为一维向量\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512*7*7, 4096),     # get [b,4096]\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),         # get [b,4096]\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 1000)         # get [b,1000]\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        conv_features = self.features(x)   # 卷积层得到特征\n",
    "        # reshape 为一维向量\n",
    "        tense_input = conv_features.view(conv_features.size(0), -1)\n",
    "        output = self.classifier(tense_input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.随机输入的数据: torch.Size([1, 3, 224, 224])\n",
      "2.模型输出: torch.Size([1, 1000])\n",
      "Wall time: 2.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "VGG16_model = VGG()\n",
    "# print(model)\n",
    "data_random = torch.Tensor(range(3*224*224))\n",
    "input = data_random.reshape([1,3,224,224])\n",
    "print('1.随机输入的数据:', input.shape)\n",
    "output = VGG16_model(Variable(input))\n",
    "print('2.模型输出:', output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方法二，完整的定义VGG网络\n",
    "# 定义VGGNet的4种结构\n",
    "cfg = {\n",
    "    'VGG11':[64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13':[64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16':[64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512,\\\n",
    "             512, 512, 'M'],\n",
    "    'VGG19':[64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, \\\n",
    "             'M', 512, 512, 512, 512, 'M']    \n",
    "}\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name, num_classes=10):\n",
    "        super().__init__()    # 输入 [b,3,224,224]\n",
    "        self.features = self._make_layers(cfg[vgg_name])    # 卷积层提取特征\n",
    "        self.classifier = nn.Sequential(\n",
    "            # fc6\n",
    "            nn.Linear(512*7*7, 4096),        # get [b,4096]\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            # fc7\n",
    "            nn.Linear(4096, 4096),           # get [b,4096]\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            # fc8\n",
    "            nn.Linear(4096, num_classes)     # get [b,num_classes]          \n",
    "        )\n",
    "        self._initialize_weights()           # 初始化权重！！！\n",
    "    def forward(self, x):\n",
    "        conv_features = self.features(x)     # 卷积提取特征 \n",
    "        tense_input = conv_features.view(conv_features.size(0), -1)   # reshape为一维向量\n",
    "        output = self.classifier(tense_input)\n",
    "        return output\n",
    "    \n",
    "    # 生成网络的层信息\n",
    "    def _make_layers(self, net_cfg):         \n",
    "        layers = []    # 将网络的结构写入到列表中\n",
    "        in_channels = 3\n",
    "        for x in net_cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]    # 将结构append到列表中\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, stride=1, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x                # 令下一层的输入为上层的输出\n",
    "        # 有了均值池化层，可以减少全连接层的个数！！！！！！\n",
    "#         layers += [nn.AvgPool2d(kernel_size=1, stride=1)] \n",
    "        return nn.Sequential(*layers)          # *代表可变参数，列表用*，字典用**\n",
    "    \n",
    "    # 初始化网络权重\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():               # 访问网络的各个模块\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0]*m.kernel_size[1]*m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2.0 /n ))    # 卷积权重初始化方法\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()                         # 卷积偏置初始为0\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)              # BN层权重初始为1\n",
    "                m.bias.data.zero_()                 # BN层偏置初始为0\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)      # fc层权重初始为高斯分布\n",
    "                m.bias.data.zero_()                 # fc层偏置初始为0                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.网络的输出: torch.Size([1, 10])\n",
      "Wall time: 2.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vgg16_net = VGG('VGG16')\n",
    "# print(vgg16_net)\n",
    "input = torch.randn([1,3,224,224])\n",
    "output = vgg16_net(Variable(input))\n",
    "print('1.网络的输出:', output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 GoogLeNet\n",
    "又称InceptionNet，2014年ImageNet冠军，参数比AlenNet少12倍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 1e-2\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.读取数据及预处理\n",
    "# Compose将各种预处理操作组合，ToTensor将图片处理为tensor，\n",
    "# Normalize(mean, variance)正则化\n",
    "data_tf = transforms.Compose([transforms.ToTensor(), \\\n",
    "                              transforms.Normalize([0.5], [0.5])])\n",
    "# 下载MNIST手写数字训练集\n",
    "train_dataset = datasets.MNIST(root='./data/cifar10', train=True, transform=data_tf, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data/cifar10', train=False, transform=data_tf)\n",
    "# 创建数据迭代器便于训练模型\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
