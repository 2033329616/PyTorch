{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1 简单的卷积网络\n",
    " ### 1.1 卷积模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (layer1): Sequential(\n",
      "    (conv1): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    (relu1): ReLU(inplace)\n",
      "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu2): ReLU(inplace)\n",
      "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu3): ReLU(inplace)\n",
      "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (fc_relu1): ReLU(inplace)\n",
      "    (fc2): Linear(in_features=512, out_features=64, bias=True)\n",
      "    (fc2_relu2): ReLU(inplace)\n",
      "    (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 定义简单的卷积网络模型\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):            # 定义网络结构\n",
    "        super().__init__()         # 输入 [batch_size,3,32,32] 3表示深度\n",
    "        layer1 = nn.Sequential()   # 叠加第1个网络层，卷积层\n",
    "        # (in_channels, out_channels, kernel_size,stride,padding)\n",
    "        layer1.add_module('conv1', nn.Conv2d(32, 3, 1, padding=1))\n",
    "        # get [batch_size, 32, 32, 32]\n",
    "        layer1.add_module('relu1', nn.ReLU(True))\n",
    "        layer1.add_module('pool1', nn.MaxPool2d(2,2))\n",
    "        # get [batch_size, 32, 16, 16]\n",
    "        self.layer1 = layer1\n",
    "        \n",
    "        layer2 = nn.Sequential()   # 定义第2个网络层\n",
    "        layer2.add_module('conv2', nn.Conv2d(32, 64, 3, 1, padding=1))\n",
    "        # get [batch_size, 64, 16, 16] \n",
    "        layer2.add_module('relu2', nn.ReLU(True))\n",
    "        layer2.add_module('pool2', nn.MaxPool2d(2,2))\n",
    "        # get [batch_size, 64, 8, 8]\n",
    "        self.layer2 = layer2\n",
    "        \n",
    "        layer3 = nn.Sequential()   # 定义第3个网络层\n",
    "        layer3.add_module('conv3', nn.Conv2d(64, 128, 3, 1, padding=1))\n",
    "        # get [batch_size, 128, 8, 8]\n",
    "        layer3.add_module('relu3', nn.ReLU(True))\n",
    "        layer3.add_module('pool3', nn.MaxPool2d(2,2))\n",
    "        # get [batch_size, 128, 4, 4]\n",
    "        self.layer3 = layer3\n",
    "        \n",
    "        layer4 = nn.Sequential()   # 定义第4个网络层，全连接层\n",
    "        layer4.add_module('fc1', nn.Linear(128*4*4, 512))\n",
    "        # get [batch_size, 512]\n",
    "        layer4.add_module('fc_relu1', nn.ReLU(True))\n",
    "        layer4.add_module('fc2', nn.Linear(512, 64))\n",
    "        # get [batch_size, 64]\n",
    "        layer4.add_module('fc2_relu2', nn.ReLU(True))\n",
    "        layer4.add_module('fc3', nn.Linear(64, 10))\n",
    "        # get [batch_size, 10]\n",
    "        self.layer4 = layer4\n",
    "    def forward(self, x):\n",
    "        conv1 = self.layer1(x)   # 前3层为卷积层\n",
    "        conv2 = self.layer2(conv1)\n",
    "        conv3 = self.layer3(conv2)\n",
    "        # 注意：全连接前要把数据的维度将为两维，-1维度长*宽*深度\n",
    "        fc_input = conv3.view(conv3.size(0), -1)  # reshape为 [batch_size, -1]\n",
    "        fc_out = self.layer4(fc_input)\n",
    "        return fc_out\n",
    "model = SimpleCNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "小结:\n",
    "- 模型层顺序：CNN+BN+ReLU+Pooling，先激活再池化;FC+ReLU\n",
    "- 输出层不用激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 提取模型的层结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|nn.Module属性|功能|实例|\n",
    "|-|-|-|\n",
    "|children()|返回下一级迭代器|self.layer1|\n",
    "|modules()|返回所有模块迭代器|self.layer1.conv1|\n",
    "|named_children()|返回模块的名称|其他功能同上|\n",
    "|named_modules()|返回模块的名称|其他功能同上|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (conv1): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    (relu1): ReLU(inplace)\n",
      "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu2): ReLU(inplace)\n",
      "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 提取已有模型中的结构\n",
    "new_model = nn.Sequential(*list(model.children())[:2])   # *代表使用可变参数\n",
    "print(new_model)\n",
    "# list(model.children())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('layer1.conv1', Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1)))\n",
      "--------------------------------------------------\n",
      "('layer2.conv2', Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n",
      "--------------------------------------------------\n",
      "('layer3.conv3', Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n",
      "--------------------------------------------------\n",
      "1.新网络的结构:\n",
      "Sequential(\n",
      "  (conv1): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 提取模型中所有的卷积层\n",
    "conv_model = nn.Sequential()\n",
    "for layer in model.named_modules():    # layer[0]层名称, layer[1]层类型\n",
    "#     print(layer)\n",
    "\n",
    "    if isinstance(layer[1], nn.Conv2d):  \n",
    "        print(layer)\n",
    "        print('-'*50)\n",
    "        conv_model.add_module(layer[0].split('.')[-1], layer[1])\n",
    "print('1.新网络的结构:')\n",
    "print(conv_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 提取参数及初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|nn.Module属性|功能|\n",
    "|-|-|\n",
    "|parameters()|返回全部参数的迭代器|\n",
    "|named_parameters()|返回模块的名称，其他功能同上|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.conv1.weight\n",
      "torch.Size([3, 32, 1, 1])\n",
      "--------------------------------------------------\n",
      "layer1.conv1.bias\n",
      "torch.Size([3])\n",
      "--------------------------------------------------\n",
      "layer2.conv2.weight\n",
      "torch.Size([64, 32, 3, 3])\n",
      "--------------------------------------------------\n",
      "layer2.conv2.bias\n",
      "torch.Size([64])\n",
      "--------------------------------------------------\n",
      "layer3.conv3.weight\n",
      "torch.Size([128, 64, 3, 3])\n",
      "--------------------------------------------------\n",
      "layer3.conv3.bias\n",
      "torch.Size([128])\n",
      "--------------------------------------------------\n",
      "layer4.fc1.weight\n",
      "torch.Size([512, 2048])\n",
      "--------------------------------------------------\n",
      "layer4.fc1.bias\n",
      "torch.Size([512])\n",
      "--------------------------------------------------\n",
      "layer4.fc2.weight\n",
      "torch.Size([64, 512])\n",
      "--------------------------------------------------\n",
      "layer4.fc2.bias\n",
      "torch.Size([64])\n",
      "--------------------------------------------------\n",
      "layer4.fc3.weight\n",
      "torch.Size([10, 64])\n",
      "--------------------------------------------------\n",
      "layer4.fc3.bias\n",
      "torch.Size([10])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 提取模型的所有参数\n",
    "for param in model.named_parameters():\n",
    "    # param[0]:层名称.weight/bias  param[1]:参数值，权重是Variable\n",
    "    print(param[0])\n",
    "    print((param[1]).data.shape)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取参数并初始化????????\n",
    "init = nn.init\n",
    "for m in model.modules():  # 访问所有模块\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.normal_(m.weight.data)\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        m.weight.data.normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
